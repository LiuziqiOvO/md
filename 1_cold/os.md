[gitee华科操作系统课题组仓库](https://gitee.com/hustos/pke-doc/blob/master/chapter1_riscv.md#machinestates)

RISC-V的寄存器

| 寄存器 | 编程接口名称 （ABI） | 描述                            | 使用                                 |
| ------ | -------------------- | ------------------------------- | ------------------------------------ |
| x0     | zero                 | Hard-wired zero                 | 硬件零                               |
| x1     | ra                   | Return address                  | 常用于保存（函数的）返回地址         |
| x2     | sp                   | Stack pointer                   | 栈顶指针                             |
| x3     | gp                   | Global pointer                  | —                                    |
| x4     | tp                   | Thread pointer                  | —                                    |
| x5-7   | t0-2                 | Temporary                       | 临时寄存器                           |
| x8     | s0/fp                | Saved Register/ Frame pointer   | （函数调用时）保存的寄存器和栈顶指针 |
| x9     | s1                   | Saved register                  | （函数调用时）保存的寄存器           |
| x10-11 | a0-1                 | Function argument/ return value | （函数调用时）的参数/函数的返回值    |
| x12-17 | a2-7                 | Function argument               | （函数调用时）的参数                 |
| x18-27 | s2-11                | Saved register                  | （函数调用时）保存的寄存器           |
| x28-31 | t3-6                 | Temporary                       | 临时寄存器                           |

RISC-V基础指令

![fig1_1](C:/Users/26557/AppData/Roaming/Typora/draftsRecover/os.assets/fig1_1.png)

C语言内嵌汇编

```
asm volatile( 
"statements"（汇编语句模板）: 
output_regs（输出部分）: 
input_regs（输入部分）:
clobbered_regs（破坏描述部分）
) ；
```

一个C语言内嵌汇编代码的例子

```c
 1 #include <stdio.h>
 2
 3 void bar()
 4 {
 5   asm volatile( "li s5, 300" );
 6 }
 7
 8 int foo( int foo_arg )
 9 {
 10   int x;
 11   asm volatile( "li s5, 500" );
 12   bar();
 13   asm volatile (//扩展内联汇编
 14      "sd s5,%0"
 15      :"=m"(x)
 16      :
 17      : "memory");
 18   printf( "x=%d\n", x );
 19   return 10;
 20 }
 21
 22 int main()
 23 {
 24   foo( 10 );
 25   return 0;
 26 }
```

//按照RISC-V规范，对于名字为s开始的寄存器，在进行函数调用时应该对其值进行保留，如果这一点被严格遵守的话，例1.1在第18行的输出就应该输出500。



但实际上编译器为了代码的效率，并未完全遵守RISC-V规范，会输出300，也就是没对寄存器做任何保护。

## 配置实验环境



## 一些命令

ldd 查看依赖的库

ps 默认打印当前中断上的进程

ps -al 是所有的进程

pstree 看进程树



echo $？

$是环境变量前缀，？代表上次运行的命令，所以这个指令会返回上条命令的返回值

末尾加&   	后台运行



内存泄露 Debug工具： valgrind

## 库

### 静态链接库

### 动态链接库





Linux 系统调用的实现

## 绪论

##### 多道程序程序设计

在计算机主存中同时存放几道相互独立的程序。这些程序在管理程序控制之下，相互穿插地运行。当某道程序因某种原因不能继续运行下去时(如等待外部设备传输数据)，管理程序便将另一道程序投入运行。

##### 脱机、联机？？？

##### 操作系统的类型：

- 批量操作系统
- 分时操作系统
- 实时操作系统：实时响应，要在规定时间内处理完，具有可靠性，可预测性





## 结构和硬件支持

**操作系统虚拟机**：硬件套上操作系统后构成了操作系统虚拟机

操作系统虚拟机对硬件裸机的扩充：

<img src="os.assets/image-20230224141453693.png" alt="image-20230224141453693" style="zoom:50%;" />



##### 系统架构	

Linux模块化向微内核发展   Windows：	拓展的微内核

##### 处理器特权级和中断



## 进程和进程管理



进程树

存在一个根进程，任何一个子进程，其父进程被kill，他就会变成根进程的子进程



**进程销毁的实现**

1. 进程自己正常结束

   main（）

   exit（）

2. 通过信号signal(软中断)实现

   kill

kill会发送一个终止信号，可以加参数，有很多种，ctrl+c也是发送一个信号SIGINT

SIGQUIT退出时会把内存写入硬盘，生成core文件

小实验，可以拦截signal

但规定kill -9不可以拦截



**进程阻塞/唤醒**

- 锁
- 等待进程或线程退出
- sleep
- read/wrte
- select,poll,epoll

> 文件读写

open close read write 

ioctl 

mmap

阻塞I/O，非阻塞I/O

同步I/O，非同步I/O

多数情况都是 非阻塞+同步I/O

select,poll,epoll是为了解决同步I/O时,可能会出现没数据就一直返回-1 again的情况，他会筛选出有数据的



### 进程之间的相互制约关系

进程互斥，进程同步

互斥：同一个全局变量不能被同时更改

同步：存储+打印



#### 临界区

临界区是进程中对公共变量 (或存储区)进行访问与修改的程序段，称为相对于该公共变量的临界区。

- 互斥访问：一次至多允许一个进程进入临界区内。
- 有限等待：一个进程不能无限地停留在临界区内，也不能无限地等待进入临界区。
- 空闲让进：当没有进程在执行临界区代码时，必须允许等待的进程或申请进入的进程进入临界区。





#### 互斥

**自旋锁spinlock**

spinlock的锁变量w本身也是一个共享变量，怎么保证w自己的互斥访问

软件实现：皮特森算法

<img src="os.assets/image-20230224150436231.png" alt="image-20230224150436231" style="zoom:100%;" />

硬件实现：x86

arm（等其他精简指令集），类似皮特森算法的硬件版本

引入了两个新指令，用来标记CPU0占用了某个内存地址



**普通锁mutex**

```cpp
   {
       while(w == 1)
       {
            保护当前进程的cpu现场；
            设置当前进程的状态为等待, 并插入到w的等待队列；
            转进程调度；
       }
       w = 1;
   }

```

开锁

```
{
 	  if(w的等待队列不为空)
       {
               移出等待队列首元素，插入到就绪队列；
               置该进程为就绪状态； 
       }
       w = 0;
    }

```



普通锁没有死循环，但是保护现场等操作本身也有几百条汇编指令了。



#### 同步——信号灯

（s，q）s是一个int，q是等待队列

s表示可用资源的个数，**s>0绿灯，s<=0红灯。**

p操作

信号灯值减少1，若减完为负，则进程被阻塞，并插入到等待队列

v操作

信号灯+1，



推论1：若信号灯s为正值，则该值等于在挂起进程之前对信号灯s可施行的P操作数、亦等于s所代表的实际还可以使用的物理资

推论2：若信号灯s为负值，则其绝对值等于登记排列在该信号灯s队列之中等待的进程个数，亦即恰好等于对信号灯s实施P操作而被挂起并进入信号灯s队列的进程数。

推论3：通常，P操作意味着请求一个资源，V操作意味着释放一个资源。在一定条件下，P操作代表挂起进程操作，而V操作代表唤醒被挂起进程的操作。



##### 互斥信号灯

![image-20230224154645582](os.assets/image-20230224154645582.png)



##### 同步信号灯

看病，开化验单，拿化验结果，回来诊断

![image-20230224154727511](os.assets/image-20230224154727511.png)





另一种：BUF区的前后各一个变量

前者表示可用的位置，后者表示有多少能拿的

![image-20230224160423190](os.assets/image-20230224160423190.png)

### 生产者_消费者问题

![image-20230224161040465](os.assets/image-20230224161040465.png)



![image-20230224161107488](os.assets/image-20230224161107488.png)

## 进程间通讯IPC

### 创建进程及应用实例

**fork( )**

`int pid=fork()`

克隆了一份新的子进程，一模一样， 甚至当前执行到的位置都是一样的。

只有fork函数的返回值不一样

**exe( )**

### 线程



### SOCKET 5









## CH5资源分配与死锁

- 并发和共享
- 共享的资源需要互斥访问
- 动态分配资源

死锁图解

![image-20221108140800855](os.assets/image-20221108140800855.png)

对于一个单核CPU，箭头要么往上（即执行P2进程），要么往右（即执行P1）进程。

阴影部分是独占区，不可以转向（中途转给别的进程用）

走不出来，即有可能发生死锁。

 **产生死锁的条件**

如果四个条件满足，一定死锁。

- 互斥条件：资源是互斥的，一次只能一个进程使用				
- 不可抢占
- 占有并等待：进程已占用了一部分，并还要申请新的互斥资源
- 环路：循环等待，大伙都进行不下去了。

**破坏死锁的上述四个条件**

- 虚拟部分硬件
- 可抢占式调度，比如CPU分时
- 静态分配，在运行前把资源申请好，再运行，但你很难在运行前确定具体空间
- ！控制分配

有序资源分配法：所有资源都给一个编号，必须按照序号次序申请

证明

### 银行家算法

![image-20221108150921005](os.assets/image-20221108150921005.png)

安全状态：

在最坏情况下，每个客户只有获得所有资源后才能归还所有资源。那么目前系统中是否有足够的资源满足其中一个进程的最大需求资源，如果能够找到，就假定该进程运行完毕后归还它所占用的所有资源，然后寻找下一个进程。如此反复下去。如果所有的进程都能运行完，所有的资源最终都被收回，则该状态是安全的。

 即存在一个资源分配序列可以使得所有进程都运行直到结束（不会导致死锁）

在有申请时，判断如果给出后整个系统是否处于安全状态 

**实际情况**

实际开发，多使用有序（分层）资源分配法

如果有回调函数，要在调用顶层模块前，先解锁。





# 内存管理

**内存映射**

逻辑地址到物理地址的转换



**拓展，未知的地址如何定位，重定向**

对于变量：如果是普通程序的全局变量

静态：m+偏移量（m是main的地址）

如果是动态链接库里的变量

获取PC，用PC相对寻址

如果是extern外部变量



对于函数：



### 虚拟内存

可是实模式下也有物理地址和虚拟地址、差别在哪？

逻辑地址与物理地址分开（完全隔离）



### 内存分配与回收

首次匹配（首次适应算法)：尽量使用内存低地址端 //空闲队列与内存顺序一致

最佳匹配（最佳适应算法)：尽量使用大小最接近的 //空闲队列按大小从小到大排序

最坏匹配（最坏适应算法)：尽量使用大小最不接近的 //空闲队列按大小从大到小排序



​	

### 页式 存储管理

背景1:为了寻找解决碎片问题的新路径，能否避开程序对连续性的要求，使得可以将程序放到不相邻的区域中。

背景2:主存容量不足，运行时能否从辅存自动调入



结构：分页，动态映射

问题：地址映射，淘汰策略



页表：逻辑地址->物理主存映射表



#### 地址转换

逻辑地址 = 页号w 页内位移x

页号 通过页表 ->块地址 s

真实地址：s + x

#### 缺页

访问的数据尚未在内存（称为缺页）

而程序能占用的主存页数是有限的，若满，需要一个淘汰算法。







如果页号从1~1000一个个存太呆了，改进，只存有数据的。

每个进程都有自己的页表，CPU切换时间片的时候，也会切换相应的页表



多级页表



扩充页表的功能

| 页号 | 主存块号 | 中断位 | ~    |
| ---- | -------- | ------ | ---- |

因为每个块都是4K对齐的，所以页表中的块号低12位其实是没用的。

中断位 = 1，页表中没找到，那么会去辅存中寻找，载入主存。如果没有空闲块了？要选一页淘汰，这页还不能删，要写入硬盘。（专用的交换分区swap file，跟内存一样大）



但是页表的存在导致读取一个数据要访问两次内存，

页表的Cache——快表



页面Cache的淘汰算法和抖动

# 



# 文件系统

### 虚拟文件系统层（VFS Layer）

https://tech.meituan.com/2017/05/19/about-desk-io.html

VFS（Virtual File System）虚拟文件系统是一种软件机制，更确切的说扮演着文件系统管理者的角色，与它相关的数据结构只存在于物理内存当中。它的作用是：屏蔽下层具体文件系统操作的差异，为上层的操作提供一个统一的接口。正是因为有了这个层次，Linux中允许众多不同的文件系统共存并且对文件的操作可以跨文件系统而执行。

VFS中包含着向物理文件系统转换的一系列数据结构，如VFS超级块、VFS的Inode、各种操作函数的转换入口等。Linux中VFS依靠四个主要的数据结构来描述其结构信息，分别为超级块、索引结点、目录项和文件对象。

1. 超级块（Super Block）：超级块对象表示一个文件系统。它存储一个已安装的文件系统的控制信息，包括文件系统名称（比如Ext2）、文件系统的大小和状态、块设备的引用和元数据信息（比如空闲列表等等）。VFS超级块存在于内存中，它在文件系统安装时建立，并且在文件系统卸载时自动删除。同时需要注意的是对于每个具体的文件系统来说，也有各自的超级块，它们存放于磁盘。
2. 索引结点（Inode）：索引结点对象存储了文件的相关元数据信息，例如：文件大小、设备标识符、用户标识符、用户组标识符等等。Inode分为两种：一种是VFS的Inode，一种是具体文件系统的Inode。前者在内存中，后者在磁盘中。所以每次其实是将磁盘中的Inode调进填充内存中的Inode，这样才是算使用了磁盘文件Inode。当创建一个文件的时候，就给文件分配了一个Inode。一个Inode只对应一个实际文件，一个文件也会只有一个Inode。
3. 目录项（Dentry）：引入目录项对象的概念主要是出于方便查找文件的目的。不同于前面的两个对象，目录项对象没有对应的磁盘数据结构，只存在于内存中。一个路径的各个组成部分，不管是目录还是普通的文件，都是一个目录项对象。如，在路径/home/source/test.java中，目录 /, home, source和文件 test.java都对应一个目录项对象。VFS在查找的时候，根据一层一层的目录项找到对应的每个目录项的Inode，那么沿着目录项进行操作就可以找到最终的文件。
4. 文件对象（File）：文件对象描述的是进程已经打开的文件。因为一个文件可以被多个进程打开，所以一个文件可以存在多个文件对象。一个文件对应的文件对象可能不是惟一的，但是其对应的索引节点和目录项对象肯定是惟一的。



![img](./os.assets/6e034503.png)



## 文件

文件名约束：长度一般不超过255，不能用shell里有意义的字符。

Linux区分大小写，WIN不区分

`ls -l`

第一个字母表示文件类别：

- -普通文件
- d目录
- c设备 
- b磁盘 

文件扩展名表示文件的使用特征

.c	.o(.obj) .so(.lib) 

在Linux下，文件扩展名只是一个提示作用，无任何约束

##### 常用的文件系统

FAT32

NTFS

ext3/4

 文件的物理结构描述了文件在辅存上安置、链接和编目的方法。

#####  常用的文件物理结构有：

- 连续文件
- 串联文件（链表式）
- 索引文件



### 文件映照表——FAT文件系统

串联文件系统，但克服了链表随机读取慢的缺点![image-20221124112438608](os.assets/image-20221124112438608.png)

FAT文件分配表：觉得磁盘的物理块（512B）太小了，要以多个块合成一个簇

相当于把链表的指针单独拿出来，存在一起（即这个FAT表）

![image-20221124112916125](os.assets/image-20221124112916125.png)

000H：空闲簇（001H：保留簇）

FFFH：文件的结尾簇

FF7H：坏簇

XXXH：文件的下一簇

现在，如果想找最后一块，还是要搜索链表。

但是，可以一次性把表加载进内存，加快速度。



## 索引文件

索引表：逻辑块-物理块的映射

引入索引区存放各个文件的索引表，根据索引表找到具体物理块号。

可以直接读写任意记录，容易扩充



#### 索引表的组织——多级索引



直接和多级索引混合

![image-20221129140844842](os.assets/image-20221129140844842.png)

## **文件存储空间的管理**

文件存储设备是分成若干个大小相等的物理块，并以块为单位来交换信息的。

哪些块已经分配出去；已经分配出去的块被哪些文件占有；（由文件目录解决）

哪些块是空闲的？**空闲块的组织，空闲块的分配与空闲块的回收**

##### 常用空闲块管理策略：

- 空闲文件目录
- 空闲块链
- 位示图

##### 位示图

用一串二进制位反映磁盘空间中分配使用情况，每个物理块对应一位，分配物理块为1，否则为0。

申请物理块时，在位示图中查找为0的位，返回对应物理块号； 归还时，将对应位转置0。

位示图描述能力强，适合各种物理结构。



## 文件目录

文件系统的核心问题：

- 信息的逻辑结构-->存储介质的物理结构
- 文件操作I/O指令

**文件目录是记录文件的名字、存放地址及其他有关文件的说明信息和控制信息的数据结构。**

树状目录文件



### 链接文件

##### 软链接

只包括文件的路径，可以是相对路径或绝对路径，并且可以跨文件系统

这不就快捷方式吗

路径可以跨文件系统，甚至可以不存在

##### 硬链接

多个目录项，都指向同一个文件（对应到同一个索引节点i_node)

![image-20221129152415927](os.assets/image-20221129152415927.png)

不能对目录使用硬链接，比如子目录指向父目录，发生混乱

可能会造成死循环。（因为硬链接相当于是真实存在一个文件，（指索引））

**什么情况下会用到链接**



`ln -sf xxx真实地址  错误地址  `

### 



## UNIX文件系统实现

文件是无结构的字节流

空闲块管理：成组链接法

目录结构：树形层次，但可拆卸（挂载)

### 



##### 索引节点

文件属性中除了名字以外的所有东西都存在一个单独的数据块(i node)

![image-20221129152140835](os.assets/image-20221129152140835.png)



注意上图中的13位就是

![image-20221129152233278](os.assets/image-20221129152233278.png)

磁盘索引节点示例

![image-20221206141013928](os.assets/image-20221206141013928.png)



### UNIX系统打开文件

当打开一个文件时，建立用户与该文件的联系，就是将辅存中的相关目录项，辅存索引节点和索引表拷贝到主存中

- 活动i节点表（全局唯一）
- 打开文件表（全局唯一）
- 用户文件描述符表（每个进程一张）

![image-20221206143752719](os.assets/image-20221206143752719.png)



### 空闲块的管理

disk:

引导区 | 管理块 | 索引节点区| 数据区

管理块（超级块）

每组100块，挑出一个块作特殊块指向下一组。

![image-20221206151316160](os.assets/image-20221206151316160.png)





## 设备管理

一般的，只有读，写，内存映射

但是不能满足所有的设备，比如声卡

- 控制块，命令转换表函数指针
- 缓冲
- 





# os_lab

```bash

# 基本上就是加上一个 riscv64-unknown-elf- 前缀

# 读elf头文件信息
riscv64-unknown-elf-readelf -h

# 了解helloworld可执行程序包含哪些程序节：
riscv64-unknown-elf-readelf -S

# 再通过查看该可执行程序的程序段组
riscv64-unknown-elf-readelf -l
```





### lab1

#### lab1_1系统调用

printu的追溯到user_lib.c中的 do_user_call( )

do_user_call函数是通过ecall指令完成系统调用的，且在执行ecall指令前，所有的参数（即do_user_call函数的8个参数）实际上都已经载入到RISC-V机器的a0到a7

ecall指令的执行将根据a0寄存器中的值获得系统调用号，并使RISC-V转到S模式（我们的操作系统内核启动时将所有的中断、异常、系统调用都代理给了S模式）的trap处理入口执行（在kernel/strap_vector.S文件中定义）：

先保存进程现场，然后把a_0（系统调用号）保存到内核堆栈，再更改sp寄存器（切换栈）

完整的切换过程：

- 1）应用程序在U模式即应用态执行，这个时候是使用的操作系统为其分配的栈（称为用户栈），这一部分参见`kernel/kernel.c`文件中`load_user_program`的实现；
- 2）应用程序调用ecall，后陷入内核，开始执行`smode_trap_vector`函数，此时使用的是操作系统内核的栈。参见`kernel/machine/mentry.S`文件中的PKE入口`_mentry`；
- 3）中断处理例程`smode_trap_vector`函数执行到第35行时，将栈切换到用户进程“自带”的“用户内核栈“，也就是`kernel/process.c`文件中`switch_to`函数的第39行所引用的`proc->kstack`，而不使用PKE内核自己的栈，

后续的执行将使用应用进程所附带的内核栈来保存执行的上下文，如函数调用、临时变量这些；最后，将应用进程中的p->trapframe->kernel_trap写入t0寄存器（第38行），并最后（第41行）调用p->trapframe->kernel_trap所指向的smode_trap_handler()函数。



#### lab1_2异常处理

了解和掌握操作系统中异常（exception）的产生原理以及处理的原则。

user/app_illegal_instruction.c文件中，我们的应用程序“企图”执行不能在用户模式（U模式）运行的特权级指令：`csrw sscratch, 0`

这类异常属于非法指令异常：CAUSE_ILLEGAL_INSTRUCTION，异常码02（见kernel/riscv.h中的定义）



PKE操作系统内核在启动时会将部分异常和中断“代理”给S模式处理，但是它是否CAUSE_ILLEGAL_INSTRUCTION这类异常也进行了代理呢？ 

在kernel/machine/minit.c的delegate_traps()函数，将部分异常代理给了S模式处理，但没有我们要的。所以是交给M模式处理的，（实际上，对于spike模拟的RISC-V平台而言，CAUSE_ILLEGAL_INSTRUCTION异常*必须*在M态处理）//M=machine 即机器模式



所以还是要找M模式的trap处理入口：M模式的trap处理入口在kernel/machine/mtrap_vector.S文件中（PKE操作系统内核在启动时（kernel/machine/minit.c文件的第104行`write_csr(mtvec, (uint64)mtrapvec);`）已经将M模式的中断处理入口指向了该函数）

在这个.S汇编文件中，经典的一堆保护，切换栈（复杂，不细写了），最终调用handle_mtrap()函数。handle_mtrap()函数在kernel/machine/mtrap.c文件中定义：

完成TODO就OK了

#### lab1_3外部中断

有一个时钟中断（模拟），然后处理这个终端（打印一个全局变量），然后设置SIP（Supervisor Interrupt Pending，即S模式的中断等待寄存器）寄存器中的SIP_SSIP位为0即可。



#### lab1_challenge

模仿printu（），在user_lib.c中添加print_traceback（）函数，调用do_user_call（），自己定义了一个常量base64+2，作系统调用编号

do_user_cal内联汇编调用ecall

经过一堆汇编指令，最后，调用p->trapframe->kernel_trap所指向的smode_trap_handler()函数。(strap.c)

然后经判断会调用handle_syscall：

```cpp
static void handle_syscall(trapframe *tf) {
  // tf->epc points to the address that our computer will jump to after the trap handling.
  // for a syscall, we should return to the NEXT instruction after its handling.
  // in RV64G, each instruction occupies exactly 32 bits (i.e., 4 Bytes)
  tf->epc += 4;
  // TODO (lab1_1): remove the panic call below, and call do_syscall (defined in
  // 参数
  long ret = 0;
  ret = do_syscall(tf->regs.a0,
                   tf->regs.a1,
                   tf->regs.a2,
                   tf->regs.a3,
                   tf->regs.a4,
                   tf->regs.a5,
                   tf->regs.a6,
                   tf->regs.a7
                 );
  tf->regs.a0 = ret;
  // 返回值？
}
```

do_syscall在syscall.c中实现







lab4

由于pke是虚拟环境，主机上的文件系统hostfs（Host File System），我们将分配一段内存作为我们的“磁盘”（即RAM Disk），创建一个简单的，名称为RFS（Ramdisk File System）的文件系统。由于有多个文件系统的存在，引入了**虚拟文件系统**（**VFS**）

![1660396457538](./os.assets/lab4.pke_fs_callgraph.png)



PKE为进程定义了一个“打开文件表”，并用一个管理数据结构proc_file_management对一个进程所打开的文件进行管理，proc_file_management结构保存了一个当前目录的dentry，以及一个“打开文件”数组opened_files，数组元素个数nfiles。该结构是每个PKE进程都有的。

kernel/proc_file.c文件中还定义了一组接口，用于进程对文件的一系列操作。这些接口包括文件打开（do_open）、文件关闭（do_close）、文件读取（do_read）、文件写（do_write）、文件读写定位（do_lseek）、获取文件状态（do_stat），甚至获取磁盘状态（do_disk_stat）。这些接口，都是在应用程序发出对应的文件操作（如open、close、read_u等）时，通过user lib，到达do_syscall，并最后被调用的





# ELF文件

ELF文件（Executable Linkable Format）是一种文件存储格式。Linux下的目标文件和可执行文件都按照该格式进行存储。https://zhuanlan.zhihu.com/p/521340262



一个 ELF 头在文件的开始，保存了路线图(road map)，







> OOM是什么

ChatGPT

"OOM" 是 "Out of Memory" 的缩写，翻译为中文是"内存耗尽"或"内存溢出"。这是指在计算机系统中，当系统无法满足程序或进程所请求的内存需求时发生的一种情况。

具体来说，当一个程序或进程请求分配一块内存（例如通过`malloc`或`new`等内存分配函数），如果系统无法提供足够的可用内存，就会发生OOM。这可能由于系统的物理内存已经用尽，或者虚拟内存（如果启用了交换或分页机制）也无法提供所需的额外内存。

在发生OOM时，操作系统通常会采取一些措施，其中最常见的是终止或杀死使用了过多内存的进程，以释放系统资源。这可以防止整个系统因为内存不足而崩溃或无法正常工作。

OOM情况通常是系统资源管理的一个重要方面，特别是在多任务和多用户环境中。开发者需要谨慎处理内存分配，确保及时释放不再需要的内存，以避免系统遭遇OOM问题。



>Page frame

"Page frame" 是指物理内存中的一个固定大小的区域，通常与虚拟内存中的一个页面大小相对应。在操作系统中，内存被划分为固定大小的块，这些块被称为“页面”（page），而在物理内存中，每个页面对应一个“page frame”。

具体来说：

1. **Page（页面）：** 虚拟内存中的一个固定大小的块，通常为4 KB或其他常见的大小。操作系统使用页面来管理进程的内存，将虚拟地址空间划分为许多页面，以便更灵活地分配和管理内存。
2. **Page Frame（页面框）：** 物理内存中的一个区域，与虚拟内存中的一个页面大小相对应。每个页面在物理内存中都有一个对应的页面框。当一个页面被加载到物理内存时，它被放置在一个空闲的页面框中。

虚拟内存中的页面和物理内存中的页面框之间建立了映射关系。操作系统使用页表（page table）来跟踪虚拟地址到物理地址的映射。当程序访问虚拟内存中的某个地址时，操作系统通过页表查找该地址对应的物理内存位置。

总的来说，page frame 是指物理内存中的页面大小的区域，用于存放从虚拟内存中加载到物理内存中的数据。
